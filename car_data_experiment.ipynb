{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#Framework for performing the experiments for the car data set\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, tree, neural_network, preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from itertools import combinations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "24\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#Import the data set and remove the rows with missing values\n",
    "car_data = pd.read_table('datasets/car/car-original.data', header=None, delim_whitespace=True)\n",
    "df = car_data.apply (pd.to_numeric, errors='coerce')\n",
    "print(df)\n",
    "clean_data = df = df.dropna()\n",
    "clean_data.reset_index(drop=True)\n",
    "npdata = clean_data.to_numpy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# print(npdata)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1.8688847367953315e-33\n",
      "1.6853164583771687e-08\n",
      "6.666826889578352e-08\n",
      "1.475383123652266e-07\n",
      "2.5660726116708893e-07\n",
      "3.9024488791150245e-07\n",
      "5.442586478615131e-07\n",
      "7.141226822005417e-07\n",
      "8.952043452831699e-07\n",
      "1.0829712933147627e-06\n",
      "1.2731664252468703e-06\n",
      "1.4619429656313333e-06\n",
      "1.645956904943538e-06\n",
      "1.8224182359332758e-06\n",
      "1.9891055713226265e-06\n",
      "2.144350678164101e-06\n",
      "2.287000298937004e-06\n",
      "2.4163625591188634e-06\n",
      "2.532144551528904e-06\n",
      "2.6343866031555004e-06\n",
      "2.7233974951186417e-06\n",
      "2.799693688869379e-06\n",
      "2.8639445208939123e-06\n",
      "2.9169244217432828e-06\n",
      "2.959472511514065e-06\n",
      "2.992459414303998e-06\n",
      "3.0167607944849945e-06\n",
      "3.0332369166304167e-06\n",
      "3.042717436306073e-06\n",
      "3.045990611149879e-06\n",
      "3.0437961555554077e-06\n",
      "3.036821027903283e-06\n",
      "3.0256975215183536e-06\n",
      "3.011003118636523e-06\n",
      "2.9932616533846596e-06\n",
      "2.972945410602886e-06\n",
      "2.950477859815801e-06\n",
      "2.9262367867345862e-06\n",
      "2.9005576382566426e-06\n",
      "2.873736941535185e-06\n",
      "1.8688847367953315e-33\n",
      "2.6195545553378962e-08\n",
      "1.045713141117957e-07\n",
      "2.3464022065866507e-07\n",
      "4.156909310146823e-07\n",
      "6.467936599244779e-07\n",
      "9.268076684310747e-07\n",
      "1.2543903648177917e-06\n",
      "1.6280078941673125e-06\n",
      "2.0459470844375593e-06\n",
      "2.5063286021488104e-06\n",
      "3.00712115854553e-06\n",
      "3.546156597605557e-06\n",
      "4.121145690607153e-06\n",
      "4.72969445818693e-06\n",
      "5.369320839897587e-06\n",
      "6.037471533118875e-06\n",
      "6.731538827666584e-06\n",
      "7.4488772693642415e-06\n",
      "8.18681999502432e-06\n",
      "8.94269459235067e-06\n",
      "9.713838351067962e-06\n",
      "1.049761278565836e-05\n",
      "1.1291417325208197e-05\n",
      "1.2092702081657888e-05\n",
      "1.2898979623902785e-05\n",
      "1.3707835701391475e-05\n",
      "1.4516938876867908e-05\n",
      "1.5324049043307468e-05\n",
      "1.6127024814917194e-05\n",
      "1.692382979576759e-05\n",
      "1.7712537742417383e-05\n",
      "1.8491336648304044e-05\n",
      "1.9258531787839215e-05\n",
      "2.001254776696677e-05\n",
      "2.0751929634287222e-05\n",
      "2.1475343112865055e-05\n",
      "2.218157401749613e-05\n",
      "2.2869526925515293e-05\n",
      "2.3538223171396362e-05\n",
      "1.8688847367953315e-33\n",
      "1.623506597054877e-10\n",
      "6.493661509841785e-10\n",
      "1.4608939682707818e-09\n",
      "2.5966514056073703e-09\n",
      "4.056225848797757e-09\n",
      "5.839075170725407e-09\n",
      "7.944528229218687e-09\n",
      "1.0371785466761269e-08\n",
      "1.3119919611200188e-08\n",
      "1.618787647619458e-08\n",
      "1.9574475860737586e-08\n",
      "2.327841254620063e-08\n",
      "2.7298257389198682e-08\n",
      "3.1632458509570285e-08\n",
      "3.627934257110669e-08\n",
      "4.1237116153494385e-08\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#define the test indices and define the test data. This data remains untouched\n",
    "random.seed(50)\n",
    "test_indices = np.unique(np.array([random.randint(0,npdata.shape[0]-1) for k in range(0,math.ceil(0.2*npdata.shape[0]))]))\n",
    "# print(test_indices)\n",
    "test_data = npdata[test_indices, :]\n",
    "test_X = test_data[:,1:]\n",
    "test_transformer = preprocessing.MinMaxScaler().fit(test_X)\n",
    "normalized_test_X = test_transformer.transform(test_X)\n",
    "real_mpg = test_data[:, 0]\n",
    "\n",
    "\n",
    "\n",
    "#set up iteration variables and parameters\n",
    "mu = 0\n",
    "#hp = 1st column, weight = 2nd column, acceleration = 3rd column\n",
    "features = [[1], [2], [3], [1,2], [1,3], [2,3], [1,2,3]] \n",
    "input_variances = np.arange(0,0.4,0.01)\n",
    "iterations = 100\n",
    "\n",
    "\n",
    "#set up arrays for the results of the models\n",
    "results = np.zeros([iterations, test_X.shape[0]])\n",
    "output_variances = np.zeros(input_variances.size)\n",
    "plot_matrix = np.zeros([len(features), input_variances.size])\n",
    "\n",
    "for j in range(0, len(features)):\n",
    "    k = 0\n",
    "    for sig in input_variances:\n",
    "        rng = np.random.default_rng(12345)\n",
    "        for i in range(0, iterations):\n",
    "            data = copy.deepcopy(npdata)\n",
    "            training_data = np.delete(data, test_indices, axis=0)\n",
    "            rows = training_data.shape[0]\n",
    "            noise_indices = rng.choice(rows-1, math.ceil(0.1*rows), replace=False)\n",
    "            training_X = training_data[:, 1:]\n",
    "            training_transformer = preprocessing.StandardScaler().fit(training_X)\n",
    "            normalized_training_X = training_transformer.transform(training_X)\n",
    "            for el in features[j]:\n",
    "                noises = rng.normal(mu, sig, noise_indices.shape)\n",
    "                normalized_training_X[noise_indices, el] += noises\n",
    "            training_y = training_data[:, 0]\n",
    "            ######################################################### LINEAR REGRESSION\n",
    "            clf = linear_model.LinearRegression()\n",
    "            ######################################################### DECISION TREE\n",
    "            # clf = tree.DecisionTreeRegressor(random_state=42)\n",
    "            ######################################################### NEURAL NET\n",
    "            # clf = neural_network.MLPRegressor(random_state=42, max_iter=200)\n",
    "            #########################################################\n",
    "            clf = clf.fit(normalized_training_X, training_y)\n",
    "            prediction_mpg = clf.predict(normalized_test_X)\n",
    "            results[i] = prediction_mpg\n",
    "        variances = np.array([np.var(results[:, k]) for k in range(0, results.shape[1])])\n",
    "        mean_output_variance = np.mean(variances)\n",
    "        print(mean_output_variance)\n",
    "        output_variances[k] = mean_output_variance\n",
    "        plot_matrix[j] = output_variances\n",
    "        k += 1\n",
    "# print(output_variances)\n",
    "print(\"done\")\n",
    "now = datetime.now()\n",
    "timestamp = datetime.timestamp(now)\n",
    "experiment_name = \"lin reg extra\"\n",
    "path = 'results/car/'\n",
    "np.savetxt(path + experiment_name + str(timestamp) + '.csv', plot_matrix, delimiter=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#Plot the outcomes\n",
    "t=0\n",
    "for arr in plot_matrix:\n",
    "    plt.plot(input_variances, arr, label=\"line \" + str(features[t]))\n",
    "    t+=1\n",
    "plt.xlabel('input variance')\n",
    "plt.ylabel('output variance')\n",
    "plt.legend()\n",
    "plt.savefig(path + experiment_name + str(timestamp) + '.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "timestamp = datetime.timestamp(now)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}